{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas numpy networkx matplotlib scikit-learn --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"collected_posts.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Carica i dati dal CSV\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "# Seleziona le colonne rilevanti\n",
    "columns_to_keep = ['Username', 'User ID', 'Post ID', 'Like Count', 'Caption Text', 'Caption Created At (UTC)']\n",
    "df_clean = df[columns_to_keep].copy()\n",
    "\n",
    "# Converti 'Caption Created At (UTC)' in formato datetime\n",
    "df_clean['Caption Created At (UTC)'] = pd.to_datetime(df_clean['Caption Created At (UTC)'], errors='coerce')\n",
    "\n",
    "# Rimuovi righe con valori mancanti\n",
    "df_clean = df_clean.dropna(subset=['User ID', 'Post ID', 'Like Count'])\n",
    "df_clean = df_clean.drop_duplicates(subset='Post ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identificazione degli utenti influenti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creazione del grafo delle interazioni\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Aggiungi nodi e archi in base ai like\n",
    "for _, row in df_clean.iterrows():\n",
    "    user_id = row['User ID']\n",
    "    post_id = f'post_{row[\"Post ID\"]}'\n",
    "    like_count = row['Like Count']\n",
    "    \n",
    "    G.add_node(user_id)\n",
    "    G.add_edge(user_id, post_id, weight=like_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Misure di centralità"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 utenti per Degree Centrality:\n",
      "[(62926993725, 0.011049723756906077), (58605518020, 0.007366482504604052), (59654151507, 0.007366482504604052), (68680407401, 0.006445672191528545), (12884127867, 0.0055248618784530384), (65293283875, 0.0055248618784530384), (22148830740, 0.004604051565377533), (2040587559, 0.003683241252302026), (2129098119, 0.003683241252302026), (45432108355, 0.0027624309392265192)]\n",
      "\n",
      "Top 10 utenti per Closeness Centrality:\n",
      "[('post_3474452509664264656', 0.0009208103130755065), ('post_3474350927834661356', 0.0009208103130755065), ('post_3473932439324360592', 0.0009208103130755065), ('post_3473768383085032947', 0.0009208103130755065), ('post_3474245558295728334', 0.0009208103130755065), ('post_3473630813577459268', 0.0009208103130755065), ('post_3473576320682720960', 0.0009208103130755065), ('post_3473565258301806527', 0.0009208103130755065), ('post_3446085903746401933', 0.0009208103130755065), ('post_3425126533460802710', 0.0009208103130755065)]\n",
      "\n",
      "Top 10 utenti per Betweenness Centrality:\n",
      "[(25997793037, 0.0), ('post_3474452509664264656', 0.0), (62926993725, 0.0), ('post_3474350927834661356', 0.0), ('post_3473932439324360592', 0.0), ('post_3473768383085032947', 0.0), (216860380, 0.0), ('post_3474245558295728334', 0.0), ('post_3473630813577459268', 0.0), (37550233116, 0.0)]\n",
      "\n",
      "Top 10 utenti per PageRank:\n",
      "[('post_3474245558295728334', 0.0013706360349240217), ('post_3473576320682720960', 0.0013706360349240217), ('post_3473565258301806527', 0.0013706360349240217), ('post_3446085903746401933', 0.0013706360349240217), ('post_3425126533460802710', 0.0013706360349240217), ('post_3463521913939771771', 0.0013706360349240217), ('post_3473655456187232280', 0.0013706360349240217), ('post_3474467704456793103', 0.0013706360349240217), ('post_3474506153347757658', 0.0013706360349240217), ('post_3474497417981634959', 0.0013706360349240217)]\n",
      "\n",
      "Top 10 utenti per Eigenvector Centrality:\n",
      "[('post_3474452509664264656', 0.04120338063660146), ('post_3474350927834661356', 0.04120338063660146), ('post_3473932439324360592', 0.04120338063660146), ('post_3473768383085032947', 0.04120338063660146), ('post_3474245558295728334', 0.04120338063660146), ('post_3473630813577459268', 0.04120338063660146), ('post_3473576320682720960', 0.04120338063660146), ('post_3473565258301806527', 0.04120338063660146), ('post_3446085903746401933', 0.04120338063660146), ('post_3425126533460802710', 0.04120338063660146)]\n",
      "\n",
      "Top 10 utenti per Katz Centrality:\n",
      "[('post_3474452509664264656', 0.031613764044534344), ('post_3474350927834661356', 0.031613764044534344), ('post_3473932439324360592', 0.031613764044534344), ('post_3473768383085032947', 0.031613764044534344), ('post_3474245558295728334', 0.031613764044534344), ('post_3473630813577459268', 0.031613764044534344), ('post_3473576320682720960', 0.031613764044534344), ('post_3473565258301806527', 0.031613764044534344), ('post_3446085903746401933', 0.031613764044534344), ('post_3425126533460802710', 0.031613764044534344)]\n",
      "\n",
      "Top 10 utenti per HITS Hub Scores:\n",
      "[(37518044899, 1.0), (22492190217, 5.768010462893096e-20), (2024680717, 1.2965709847615539e-20), (1624593034, 9.45461957337824e-21), (5343012897, 9.301473776419402e-21), (66966525567, 8.614509420223791e-21), (1714462254, 7.784671969558373e-21), (2107105476, 7.14950046604196e-21), (58768100386, 6.7199498867738696e-21), (11194451659, 6.659871656055871e-21)]\n",
      "\n",
      "Top 10 utenti per HITS Authority Scores:\n",
      "[('post_3470553449201335218', 1.0000000000000002), ('post_3417897543369409997', 1.1412103235964047e-17), (1924352058, 1.106131322795267e-17), ('post_3457463115262158990', 1.0726710179932726e-17), ('post_3267914197100417827', 9.678942148817579e-18), (5751928718, 9.597074776093507e-18), (53779270027, 9.580031672145093e-18), ('post_3169149386202071735', 9.45395776455384e-18), (10224436212, 9.438876146250301e-18), (7026477935, 8.620568118456765e-18)]\n"
     ]
    }
   ],
   "source": [
    "# Degree Centrality\n",
    "degree_centrality = nx.degree_centrality(G)\n",
    "\n",
    "# Closeness Centrality\n",
    "closeness_centrality = nx.closeness_centrality(G)\n",
    "\n",
    "# Betweenness Centrality\n",
    "betweenness_centrality = nx.betweenness_centrality(G, normalized=True, weight='weight')\n",
    "\n",
    "# PageRank\n",
    "pagerank = nx.pagerank(G, alpha=0.85)\n",
    "\n",
    "# Katz Centrality\n",
    "katz_centrality = nx.katz_centrality(G, alpha=0.1, beta=1.0, max_iter=1000, tol=1e-06)\n",
    "\n",
    "# Bonacich Centrality (classic power centrality)\n",
    "# NetworkX non implementa direttamente la Bonacich Centrality. Tuttavia, puoi utilizzare la centralità di potenza (power centrality)\n",
    "# che è una generalizzazione di quella di Bonacich.\n",
    "# Per implementare Bonacich centrality, dobbiamo definire la formula o usare librerie esterne, ma qui applichiamo power centrality.\n",
    "eigenvector_centrality = nx.eigenvector_centrality(G, max_iter=1000)\n",
    "\n",
    "# HITS Algorithm\n",
    "hits_hub, hits_authority = nx.hits(G, max_iter=1000, tol=1e-08)\n",
    "\n",
    "# Mostra i top 10 utenti per ciascuna metrica\n",
    "print(\"Top 10 utenti per Degree Centrality:\")\n",
    "print(sorted(degree_centrality.items(), key=lambda x: x[1], reverse=True)[:10])\n",
    "\n",
    "print(\"\\nTop 10 utenti per Closeness Centrality:\")\n",
    "print(sorted(closeness_centrality.items(), key=lambda x: x[1], reverse=True)[:10])\n",
    "\n",
    "print(\"\\nTop 10 utenti per Betweenness Centrality:\")\n",
    "print(sorted(betweenness_centrality.items(), key=lambda x: x[1], reverse=True)[:10])\n",
    "\n",
    "print(\"\\nTop 10 utenti per PageRank:\")\n",
    "print(sorted(pagerank.items(), key=lambda x: x[1], reverse=True)[:10])\n",
    "\n",
    "print(\"\\nTop 10 utenti per Eigenvector Centrality:\")\n",
    "print(sorted(eigenvector_centrality.items(), key=lambda x: x[1], reverse=True)[:10])\n",
    "\n",
    "print(\"\\nTop 10 utenti per Katz Centrality:\")\n",
    "print(sorted(katz_centrality.items(), key=lambda x: x[1], reverse=True)[:10])\n",
    "\n",
    "#print(\"\\nTop 10 utenti per Bonacich (Power) Centrality:\")\n",
    "#print(sorted(power_centrality.items(), key=lambda x: x[1], reverse=True)[:10])\n",
    "\n",
    "print(\"\\nTop 10 utenti per HITS Hub Scores:\")\n",
    "print(sorted(hits_hub.items(), key=lambda x: x[1], reverse=True)[:10])\n",
    "\n",
    "print(\"\\nTop 10 utenti per HITS Authority Scores:\")\n",
    "print(sorted(hits_authority.items(), key=lambda x: x[1], reverse=True)[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering and Community Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from networkx.algorithms.community import modularity_max\n",
    "# Modularity-based community detection\n",
    "#modular_communities = modularity_max(G)\n",
    "\n",
    "from networkx.algorithms.community import girvan_newman\n",
    "\n",
    "# Perform divisive clustering using betweenness-based method\n",
    "gn_communities = list(girvan_newman(G))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diffusion Modeling: Independent Cascade (IC) and Linear Threshold (LT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def independent_cascade(G, seeds, steps=5):\n",
    "    active = set(seeds)\n",
    "    new_active = set(seeds)\n",
    "    for _ in range(steps):\n",
    "        next_active = set()\n",
    "        for node in new_active:\n",
    "            for neighbor in G.neighbors(node):\n",
    "                if neighbor not in active and np.random.rand() < G[node][neighbor].get('weight', 0.1):\n",
    "                    next_active.add(neighbor)\n",
    "        new_active = next_active - active\n",
    "        active.update(new_active)\n",
    "        if not new_active:\n",
    "            break\n",
    "    return active\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_threshold(G, seeds, steps=5):\n",
    "    active = set(seeds)\n",
    "    thresholds = {n: np.random.uniform(0, 1) for n in G.nodes()}\n",
    "    for _ in range(steps):\n",
    "        new_active = set()\n",
    "        for node in G.nodes():\n",
    "            if node not in active:\n",
    "                neighbors = list(G.neighbors(node))\n",
    "                influence = sum(1 for n in neighbors if n in active)\n",
    "                if influence / len(neighbors) > thresholds[node]:\n",
    "                    new_active.add(node)\n",
    "        active.update(new_active)\n",
    "        if not new_active:\n",
    "            break\n",
    "    return active\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining Models and Community Detection for Propagation Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the Girvan-Newman algorithm for community detection\n",
    "comp = nx.algorithms.community.girvan_newman(G)\n",
    "communities = next(comp)  # Extract the first level of communities\n",
    "\n",
    "seeds = []\n",
    "for community in communities:\n",
    "    subgraph = G.subgraph(community)\n",
    "    betweenness = nx.betweenness_centrality(subgraph)\n",
    "    leader = max(betweenness, key=betweenness.get)  # Node with the highest centrality in the community\n",
    "    seeds.append(leader)\n",
    "\n",
    "for community in communities:\n",
    "    subgraph = G.subgraph(community)\n",
    "    \n",
    "    # Ensure that seeds are in the subgraph\n",
    "    subgraph_seeds = [s for s in seeds if s in subgraph.nodes]\n",
    "    \n",
    "    # Run the Independent Cascade model on the subgraph\n",
    "    if subgraph_seeds:  # Only run if there are valid seeds\n",
    "        active_nodes = independent_cascade(subgraph, subgraph_seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score: 0.008771929824561353\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "import numpy as np\n",
    "\n",
    "# Create labels for silhouette score\n",
    "labels = {}\n",
    "for i, community in enumerate(communities):\n",
    "    for node in community:\n",
    "        labels[node] = i\n",
    "\n",
    "# Convert the labels dictionary to a list of labels corresponding to the graph nodes\n",
    "labels_list = [labels.get(node) for node in G.nodes()]\n",
    "\n",
    "# Ensure the graph is undirected (if you have a directed graph)\n",
    "if nx.is_directed(G):\n",
    "    G = G.to_undirected()\n",
    "\n",
    "# Check if the graph is connected\n",
    "if not nx.is_connected(G):\n",
    "    # Extract the largest connected component\n",
    "    largest_component = max(nx.connected_components(G), key=len)\n",
    "    G = G.subgraph(largest_component).copy()\n",
    "\n",
    "    # Filter labels for the largest component\n",
    "    labels_list = [labels[node] for node in G.nodes()]\n",
    "\n",
    "# Compute the shortest path distance matrix\n",
    "shortest_path_lengths = dict(nx.all_pairs_shortest_path_length(G))\n",
    "\n",
    "# Convert the shortest path lengths into a distance matrix\n",
    "n = len(G.nodes())\n",
    "dist_matrix = np.zeros((n, n))\n",
    "\n",
    "node_list = list(G.nodes())\n",
    "node_index = {node: idx for idx, node in enumerate(node_list)}\n",
    "\n",
    "for i, node1 in enumerate(node_list):\n",
    "    for j, node2 in enumerate(node_list):\n",
    "        if node1 == node2:\n",
    "            dist_matrix[i, j] = 0  # distance to self is 0\n",
    "        else:\n",
    "            dist_matrix[i, j] = shortest_path_lengths[node1].get(node2, np.inf)  # inf if no path exists\n",
    "\n",
    "# Calculate silhouette score based on the distance matrix\n",
    "silhouette_avg = silhouette_score(dist_matrix, labels_list, metric='precomputed')\n",
    "print(\"Silhouette Score:\", silhouette_avg)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
